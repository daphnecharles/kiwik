{"ast":null,"code":"'use strict';\n\nvar _classCallCheck = require(\"/Users/sam/Desktop/kiwik/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/sam/Desktop/kiwik/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nObject.defineProperty(exports, '__esModule', {\n  value: true\n});\n\nvar common = require('./common.js');\n\nvar token = require('./token.js');\n\nvar jump = require('./jump.js');\n\nvar defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\n\nvar Tokeniser = /*#__PURE__*/function () {\n  function Tokeniser(data) {\n    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n    _classCallCheck(this, Tokeniser);\n\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n\n  _createClass(Tokeniser, [{\n    key: \"done\",\n    value: function done() {\n      return this.pos >= this.data.length;\n    }\n  }, {\n    key: \"next\",\n    value: function next() {\n      var byt = this.data[this.pos];\n      var token = jump.quick[byt];\n\n      if (token === undefined) {\n        var decoder = jump.jump[byt];\n\n        if (!decoder) {\n          throw new Error(\"\".concat(common.decodeErrPrefix, \" no decoder for major type \").concat(byt >>> 5, \" (byte 0x\").concat(byt.toString(16).padStart(2, '0'), \")\"));\n        }\n\n        var minor = byt & 31;\n        token = decoder(this.data, this.pos, minor, this.options);\n      }\n\n      this.pos += token.encodedLength;\n      return token;\n    }\n  }]);\n\n  return Tokeniser;\n}();\n\nvar DONE = Symbol.for('DONE');\nvar BREAK = Symbol.for('BREAK');\n\nfunction tokenToArray(token, tokeniser, options) {\n  var arr = [];\n\n  for (var i = 0; i < token.value; i++) {\n    var value = tokensToObject(tokeniser, options);\n\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" got unexpected break to lengthed array\"));\n    }\n\n    if (value === DONE) {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" found array but not enough entries (got \").concat(i, \", expected \").concat(token.value, \")\"));\n    }\n\n    arr[i] = value;\n  }\n\n  return arr;\n}\n\nfunction tokenToMap(token, tokeniser, options) {\n  var useMaps = options.useMaps === true;\n  var obj = useMaps ? undefined : {};\n  var m = useMaps ? new Map() : undefined;\n\n  for (var i = 0; i < token.value; i++) {\n    var key = tokensToObject(tokeniser, options);\n\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" got unexpected break to lengthed map\"));\n    }\n\n    if (key === DONE) {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no key], expected \").concat(token.value, \")\"));\n    }\n\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" non-string keys not supported (got \").concat(typeof key, \")\"));\n    }\n\n    var value = tokensToObject(tokeniser, options);\n\n    if (value === DONE) {\n      throw new Error(\"\".concat(common.decodeErrPrefix, \" found map but not enough entries (got \").concat(i, \" [no value], expected \").concat(token.value, \")\"));\n    }\n\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n\n  return useMaps ? m : obj;\n}\n\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n\n  var token$1 = tokeniser.next();\n\n  if (token$1.type === token.Type.break) {\n    return BREAK;\n  }\n\n  if (token$1.type.terminal) {\n    return token$1.value;\n  }\n\n  if (token$1.type === token.Type.array) {\n    return tokenToArray(token$1, tokeniser, options);\n  }\n\n  if (token$1.type === token.Type.map) {\n    return tokenToMap(token$1, tokeniser, options);\n  }\n\n  if (token$1.type === token.Type.tag) {\n    if (options.tags && typeof options.tags[token$1.value] === 'function') {\n      var tagged = tokensToObject(tokeniser, options);\n      return options.tags[token$1.value](tagged);\n    }\n\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" tag not supported (\").concat(token$1.value, \")\"));\n  }\n\n  throw new Error('unsupported');\n}\n\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" data to decode must be a Uint8Array\"));\n  }\n\n  options = Object.assign({}, defaultDecodeOptions, options);\n  var tokeniser = options.tokenizer || new Tokeniser(data, options);\n  var decoded = tokensToObject(tokeniser, options);\n\n  if (decoded === DONE) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" did not find any content to decode\"));\n  }\n\n  if (decoded === BREAK) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" got unexpected break\"));\n  }\n\n  if (!tokeniser.done()) {\n    throw new Error(\"\".concat(common.decodeErrPrefix, \" too many terminals, data makes no sense\"));\n  }\n\n  return decoded;\n}\n\nexports.Tokeniser = Tokeniser;\nexports.decode = decode;\nexports.tokensToObject = tokensToObject;","map":{"version":3,"sources":["/Users/sam/Desktop/kiwik/node_modules/cborg/cjs/lib/decode.js"],"names":["Object","defineProperty","exports","value","common","require","token","jump","defaultDecodeOptions","strict","allowIndefinite","allowUndefined","allowBigInt","Tokeniser","data","options","pos","length","byt","quick","undefined","decoder","Error","decodeErrPrefix","toString","padStart","minor","encodedLength","DONE","Symbol","for","BREAK","tokenToArray","tokeniser","arr","i","tokensToObject","Infinity","tokenToMap","useMaps","obj","m","Map","key","set","done","token$1","next","type","Type","break","terminal","array","map","tag","tags","tagged","decode","Uint8Array","assign","tokenizer","decoded"],"mappings":"AAAA;;;;;;AAEAA,MAAM,CAACC,cAAP,CAAsBC,OAAtB,EAA+B,YAA/B,EAA6C;AAAEC,EAAAA,KAAK,EAAE;AAAT,CAA7C;;AAEA,IAAIC,MAAM,GAAGC,OAAO,CAAC,aAAD,CAApB;;AACA,IAAIC,KAAK,GAAGD,OAAO,CAAC,YAAD,CAAnB;;AACA,IAAIE,IAAI,GAAGF,OAAO,CAAC,WAAD,CAAlB;;AAEA,IAAMG,oBAAoB,GAAG;AAC3BC,EAAAA,MAAM,EAAE,KADmB;AAE3BC,EAAAA,eAAe,EAAE,IAFU;AAG3BC,EAAAA,cAAc,EAAE,IAHW;AAI3BC,EAAAA,WAAW,EAAE;AAJc,CAA7B;;IAMMC,S;AACJ,qBAAYC,IAAZ,EAAgC;AAAA,QAAdC,OAAc,uEAAJ,EAAI;;AAAA;;AAC9B,SAAKC,GAAL,GAAW,CAAX;AACA,SAAKF,IAAL,GAAYA,IAAZ;AACA,SAAKC,OAAL,GAAeA,OAAf;AACD;;;;WACD,gBAAO;AACL,aAAO,KAAKC,GAAL,IAAY,KAAKF,IAAL,CAAUG,MAA7B;AACD;;;WACD,gBAAO;AACL,UAAMC,GAAG,GAAG,KAAKJ,IAAL,CAAU,KAAKE,GAAf,CAAZ;AACA,UAAIV,KAAK,GAAGC,IAAI,CAACY,KAAL,CAAWD,GAAX,CAAZ;;AACA,UAAIZ,KAAK,KAAKc,SAAd,EAAyB;AACvB,YAAMC,OAAO,GAAGd,IAAI,CAACA,IAAL,CAAUW,GAAV,CAAhB;;AACA,YAAI,CAACG,OAAL,EAAc;AACZ,gBAAM,IAAIC,KAAJ,WAAclB,MAAM,CAACmB,eAArB,wCAAoEL,GAAG,KAAK,CAA5E,sBAA2FA,GAAG,CAACM,QAAJ,CAAa,EAAb,EAAiBC,QAAjB,CAA0B,CAA1B,EAA6B,GAA7B,CAA3F,OAAN;AACD;;AACD,YAAMC,KAAK,GAAGR,GAAG,GAAG,EAApB;AACAZ,QAAAA,KAAK,GAAGe,OAAO,CAAC,KAAKP,IAAN,EAAY,KAAKE,GAAjB,EAAsBU,KAAtB,EAA6B,KAAKX,OAAlC,CAAf;AACD;;AACD,WAAKC,GAAL,IAAYV,KAAK,CAACqB,aAAlB;AACA,aAAOrB,KAAP;AACD;;;;;;AAEH,IAAMsB,IAAI,GAAGC,MAAM,CAACC,GAAP,CAAW,MAAX,CAAb;AACA,IAAMC,KAAK,GAAGF,MAAM,CAACC,GAAP,CAAW,OAAX,CAAd;;AACA,SAASE,YAAT,CAAsB1B,KAAtB,EAA6B2B,SAA7B,EAAwClB,OAAxC,EAAiD;AAC/C,MAAMmB,GAAG,GAAG,EAAZ;;AACA,OAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG7B,KAAK,CAACH,KAA1B,EAAiCgC,CAAC,EAAlC,EAAsC;AACpC,QAAMhC,KAAK,GAAGiC,cAAc,CAACH,SAAD,EAAYlB,OAAZ,CAA5B;;AACA,QAAIZ,KAAK,KAAK4B,KAAd,EAAqB;AACnB,UAAIzB,KAAK,CAACH,KAAN,KAAgBkC,QAApB,EAA8B;AAC5B;AACD;;AACD,YAAM,IAAIf,KAAJ,WAAclB,MAAM,CAACmB,eAArB,6CAAN;AACD;;AACD,QAAIpB,KAAK,KAAKyB,IAAd,EAAoB;AAClB,YAAM,IAAIN,KAAJ,WAAclB,MAAM,CAACmB,eAArB,sDAAkFY,CAAlF,wBAAmG7B,KAAK,CAACH,KAAzG,OAAN;AACD;;AACD+B,IAAAA,GAAG,CAACC,CAAD,CAAH,GAAShC,KAAT;AACD;;AACD,SAAO+B,GAAP;AACD;;AACD,SAASI,UAAT,CAAoBhC,KAApB,EAA2B2B,SAA3B,EAAsClB,OAAtC,EAA+C;AAC7C,MAAMwB,OAAO,GAAGxB,OAAO,CAACwB,OAAR,KAAoB,IAApC;AACA,MAAMC,GAAG,GAAGD,OAAO,GAAGnB,SAAH,GAAe,EAAlC;AACA,MAAMqB,CAAC,GAAGF,OAAO,GAAG,IAAIG,GAAJ,EAAH,GAAetB,SAAhC;;AACA,OAAK,IAAIe,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG7B,KAAK,CAACH,KAA1B,EAAiCgC,CAAC,EAAlC,EAAsC;AACpC,QAAMQ,GAAG,GAAGP,cAAc,CAACH,SAAD,EAAYlB,OAAZ,CAA1B;;AACA,QAAI4B,GAAG,KAAKZ,KAAZ,EAAmB;AACjB,UAAIzB,KAAK,CAACH,KAAN,KAAgBkC,QAApB,EAA8B;AAC5B;AACD;;AACD,YAAM,IAAIf,KAAJ,WAAclB,MAAM,CAACmB,eAArB,2CAAN;AACD;;AACD,QAAIoB,GAAG,KAAKf,IAAZ,EAAkB;AAChB,YAAM,IAAIN,KAAJ,WAAclB,MAAM,CAACmB,eAArB,oDAAgFY,CAAhF,iCAA0G7B,KAAK,CAACH,KAAhH,OAAN;AACD;;AACD,QAAIoC,OAAO,KAAK,IAAZ,IAAoB,OAAOI,GAAP,KAAe,QAAvC,EAAiD;AAC/C,YAAM,IAAIrB,KAAJ,WAAclB,MAAM,CAACmB,eAArB,iDAA6E,OAAOoB,GAApF,OAAN;AACD;;AACD,QAAMxC,KAAK,GAAGiC,cAAc,CAACH,SAAD,EAAYlB,OAAZ,CAA5B;;AACA,QAAIZ,KAAK,KAAKyB,IAAd,EAAoB;AAClB,YAAM,IAAIN,KAAJ,WAAclB,MAAM,CAACmB,eAArB,oDAAgFY,CAAhF,mCAA4G7B,KAAK,CAACH,KAAlH,OAAN;AACD;;AACD,QAAIoC,OAAJ,EAAa;AACXE,MAAAA,CAAC,CAACG,GAAF,CAAMD,GAAN,EAAWxC,KAAX;AACD,KAFD,MAEO;AACLqC,MAAAA,GAAG,CAACG,GAAD,CAAH,GAAWxC,KAAX;AACD;AACF;;AACD,SAAOoC,OAAO,GAAGE,CAAH,GAAOD,GAArB;AACD;;AACD,SAASJ,cAAT,CAAwBH,SAAxB,EAAmClB,OAAnC,EAA4C;AAC1C,MAAIkB,SAAS,CAACY,IAAV,EAAJ,EAAsB;AACpB,WAAOjB,IAAP;AACD;;AACD,MAAMkB,OAAO,GAAGb,SAAS,CAACc,IAAV,EAAhB;;AACA,MAAID,OAAO,CAACE,IAAR,KAAiB1C,KAAK,CAAC2C,IAAN,CAAWC,KAAhC,EAAuC;AACrC,WAAOnB,KAAP;AACD;;AACD,MAAIe,OAAO,CAACE,IAAR,CAAaG,QAAjB,EAA2B;AACzB,WAAOL,OAAO,CAAC3C,KAAf;AACD;;AACD,MAAI2C,OAAO,CAACE,IAAR,KAAiB1C,KAAK,CAAC2C,IAAN,CAAWG,KAAhC,EAAuC;AACrC,WAAOpB,YAAY,CAACc,OAAD,EAAUb,SAAV,EAAqBlB,OAArB,CAAnB;AACD;;AACD,MAAI+B,OAAO,CAACE,IAAR,KAAiB1C,KAAK,CAAC2C,IAAN,CAAWI,GAAhC,EAAqC;AACnC,WAAOf,UAAU,CAACQ,OAAD,EAAUb,SAAV,EAAqBlB,OAArB,CAAjB;AACD;;AACD,MAAI+B,OAAO,CAACE,IAAR,KAAiB1C,KAAK,CAAC2C,IAAN,CAAWK,GAAhC,EAAqC;AACnC,QAAIvC,OAAO,CAACwC,IAAR,IAAgB,OAAOxC,OAAO,CAACwC,IAAR,CAAaT,OAAO,CAAC3C,KAArB,CAAP,KAAuC,UAA3D,EAAuE;AACrE,UAAMqD,MAAM,GAAGpB,cAAc,CAACH,SAAD,EAAYlB,OAAZ,CAA7B;AACA,aAAOA,OAAO,CAACwC,IAAR,CAAaT,OAAO,CAAC3C,KAArB,EAA4BqD,MAA5B,CAAP;AACD;;AACD,UAAM,IAAIlC,KAAJ,WAAclB,MAAM,CAACmB,eAArB,iCAA6DuB,OAAO,CAAC3C,KAArE,OAAN;AACD;;AACD,QAAM,IAAImB,KAAJ,CAAU,aAAV,CAAN;AACD;;AACD,SAASmC,MAAT,CAAgB3C,IAAhB,EAAsBC,OAAtB,EAA+B;AAC7B,MAAI,EAAED,IAAI,YAAY4C,UAAlB,CAAJ,EAAmC;AACjC,UAAM,IAAIpC,KAAJ,WAAclB,MAAM,CAACmB,eAArB,0CAAN;AACD;;AACDR,EAAAA,OAAO,GAAGf,MAAM,CAAC2D,MAAP,CAAc,EAAd,EAAkBnD,oBAAlB,EAAwCO,OAAxC,CAAV;AACA,MAAMkB,SAAS,GAAGlB,OAAO,CAAC6C,SAAR,IAAqB,IAAI/C,SAAJ,CAAcC,IAAd,EAAoBC,OAApB,CAAvC;AACA,MAAM8C,OAAO,GAAGzB,cAAc,CAACH,SAAD,EAAYlB,OAAZ,CAA9B;;AACA,MAAI8C,OAAO,KAAKjC,IAAhB,EAAsB;AACpB,UAAM,IAAIN,KAAJ,WAAclB,MAAM,CAACmB,eAArB,yCAAN;AACD;;AACD,MAAIsC,OAAO,KAAK9B,KAAhB,EAAuB;AACrB,UAAM,IAAIT,KAAJ,WAAclB,MAAM,CAACmB,eAArB,2BAAN;AACD;;AACD,MAAI,CAACU,SAAS,CAACY,IAAV,EAAL,EAAuB;AACrB,UAAM,IAAIvB,KAAJ,WAAclB,MAAM,CAACmB,eAArB,8CAAN;AACD;;AACD,SAAOsC,OAAP;AACD;;AAED3D,OAAO,CAACW,SAAR,GAAoBA,SAApB;AACAX,OAAO,CAACuD,MAAR,GAAiBA,MAAjB;AACAvD,OAAO,CAACkC,cAAR,GAAyBA,cAAzB","sourcesContent":["'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar common = require('./common.js');\nvar token = require('./token.js');\nvar jump = require('./jump.js');\n\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  next() {\n    const byt = this.data[this.pos];\n    let token = jump.quick[byt];\n    if (token === undefined) {\n      const decoder = jump.jump[byt];\n      if (!decoder) {\n        throw new Error(`${ common.decodeErrPrefix } no decoder for major type ${ byt >>> 5 } (byte 0x${ byt.toString(16).padStart(2, '0') })`);\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n    this.pos += token.encodedLength;\n    return token;\n  }\n}\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ common.decodeErrPrefix } got unexpected break to lengthed array`);\n    }\n    if (value === DONE) {\n      throw new Error(`${ common.decodeErrPrefix } found array but not enough entries (got ${ i }, expected ${ token.value })`);\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ common.decodeErrPrefix } got unexpected break to lengthed map`);\n    }\n    if (key === DONE) {\n      throw new Error(`${ common.decodeErrPrefix } found map but not enough entries (got ${ i } [no key], expected ${ token.value })`);\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${ common.decodeErrPrefix } non-string keys not supported (got ${ typeof key })`);\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${ common.decodeErrPrefix } found map but not enough entries (got ${ i } [no value], expected ${ token.value })`);\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  const token$1 = tokeniser.next();\n  if (token$1.type === token.Type.break) {\n    return BREAK;\n  }\n  if (token$1.type.terminal) {\n    return token$1.value;\n  }\n  if (token$1.type === token.Type.array) {\n    return tokenToArray(token$1, tokeniser, options);\n  }\n  if (token$1.type === token.Type.map) {\n    return tokenToMap(token$1, tokeniser, options);\n  }\n  if (token$1.type === token.Type.tag) {\n    if (options.tags && typeof options.tags[token$1.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token$1.value](tagged);\n    }\n    throw new Error(`${ common.decodeErrPrefix } tag not supported (${ token$1.value })`);\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${ common.decodeErrPrefix } data to decode must be a Uint8Array`);\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${ common.decodeErrPrefix } did not find any content to decode`);\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${ common.decodeErrPrefix } got unexpected break`);\n  }\n  if (!tokeniser.done()) {\n    throw new Error(`${ common.decodeErrPrefix } too many terminals, data makes no sense`);\n  }\n  return decoded;\n}\n\nexports.Tokeniser = Tokeniser;\nexports.decode = decode;\nexports.tokensToObject = tokensToObject;\n"]},"metadata":{},"sourceType":"script"}